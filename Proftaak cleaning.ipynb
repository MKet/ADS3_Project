{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('numpy version:', np.__version__)\n",
    "print('pandas version:', pd.__version__)\n",
    "print('scikit-learn version:', sk.__version__)\n",
    "print('matplotlib version:', matplotlib.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = 'data/'\n",
    "filename = 'dataset_informa.csv'\n",
    "df = pd.read_csv(datafolder + filename, sep=',', low_memory=False, encoding = 'ISO-8859-1')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Primary_Agency_ID: When this column data is missing/99999 we are going to replace it with the Agency_ID. \n",
    "# We can not find any way to associate a primary agency with the agency in question so will replace it with its ID.\n",
    "df['PRIMARY_AGENCY_ID'] = np.where(df['PRIMARY_AGENCY_ID'] == 0, df['PRIMARY_AGENCY_ID'], df['AGENCY_ID'])\n",
    "\n",
    "# Prev_Poly_Inforce_QTY: Contains 99999 values. \n",
    "# These values mean there are no previous years or this year did not have data (CL).\n",
    "# These values will be replaces by 0\n",
    "df['PREV_POLY_INFORCE_QTY'] = df['PREV_POLY_INFORCE_QTY'].replace(99999,0)\n",
    "\n",
    "# Agency_appointment_year: 5000 missing data, irrelevant column, will be replaced with average.\n",
    "mean = df['AGENCY_APPOINTMENT_YEAR'].mean()\n",
    "df['AGENCY_APPOINTMENT_YEAR'].replace(99999, mean) \n",
    "\n",
    "# Active_Producers, Max_age and min_age: \n",
    "# If the amount of producers is not set (99999) this can be set to 0, this also goes for max and min age.\n",
    "df['ACTIVE_PRODUCERS'].replace(99999, 0) \n",
    "df['MAX_AGE'].replace(99999, 0) \n",
    "df['MIN_AGE'].replace(99999, 0) \n",
    "\n",
    "# (VENDOR)_START_YEAR: Values are varied between 1994 and 2015. \n",
    "# When the value is missing (99999) the vendor was not used. \n",
    "# All 99999 values can be replaced with 0.\n",
    "df['PL_START_YEAR'].replace(99999, 0)\n",
    "df['CL_START_YEAR'].replace(99999, 0)\n",
    "\n",
    "# (VENDOR)_END _YEAR: The year the agency stopped using the vendor. \n",
    "# This can either mean the vendor is never used or the vendor is still in use. \n",
    "# If the vendor has never been used we can replace the value with 0, if the vendor is still in use we can replace it with 1.\n",
    "df['CL_END_YEAR'] = np.where(df['CL_START_YEAR'] == 0, 0, 1)\n",
    "df['PL_END_YEAR'] = np.where(df['PL_START_YEAR'] == 0, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get a list of all values needing to be recalculated per item\n",
    "recal = [\"POLY_INFORCE_QTY\", \"NB_WRTN_PREM_AMT\", \"WRTN_PREM_AMT\", \"PRD_ERND_PREM_AMT\", \"PRD_INCRD_LOSSES_AMT\"]\n",
    "df_incomplete = df[(df[\"MONTHS\"] != 12)]\n",
    "df_filtered = df_incomplete\n",
    "for index, row in df_filtered.iterrows():\n",
    "    #Amount of months\n",
    "    months = row[\"MONTHS\"]\n",
    "    for column in recal:\n",
    "        newvalue = row[column] * (12 - months) #Value times amount of months missing\n",
    "        df_filtered.set_value(index, column, newvalue) #Set new row in dataset\n",
    "    row[\"MONTHS\"] = 12 #Reset the months to be 12\n",
    "df_filtered[recal].head(5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RETENTION_RATIO = RETENTION_POLY_QTY / PREV_POLY_INFORCE_QTY\n",
    "#LOSS_RATIO = PRD_INCRD_LOSSES_AMT / WRTN_PREM_AMT\n",
    "\n",
    "for index, row in df_filtered.iterrows():\n",
    "    if (row[\"WRTN_PREM_AMT\"] > 0) and (row[\"PRD_INCRD_LOSSES_AMT\"] > 0):\n",
    "        df_filtered.set_value(index, \"LOSS_RATIO\", row[\"PRD_INCRD_LOSSES_AMT\"] / row[\"WRTN_PREM_AMT\"])\n",
    "    else:\n",
    "        df_filtered.set_value(index, \"LOSS_RATIO\", 0)\n",
    "    if (row[\"PREV_POLY_INFORCE_QTY\"] > 0) and (row[\"RETENTION_POLY_QTY\"] > 0):\n",
    "        df_filtered.set_value(index, \"RETENTION_RATIO\", row[\"RETENTION_POLY_QTY\"] / row[\"PREV_POLY_INFORCE_QTY\"])\n",
    "    else:\n",
    "        df_filtered.set_value(index, \"RETENTION_RATIO\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_average = df\n",
    "average = [\"PREV_POLY_INFORCE_QTY\",\"POLY_INFORCE_QTY\", \"NB_WRTN_PREM_AMT\", \"WRTN_PREM_AMT\", \"PRD_ERND_PREM_AMT\"]\n",
    "\n",
    "states = df_average.STATE_ABBR.unique()\n",
    "prod_line = df_average.PROD_LINE.unique()\n",
    "   \n",
    "state_dict = {}    \n",
    "for state in states:\n",
    "    for line in prod_line:\n",
    "        state_mean = df_average[(df_average[\"STATE_ABBR\"] == state) & (df_average[\"PROD_LINE\"] == line)].mean()\n",
    "        state_dict[(state, line)] = state_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_average.iterrows():\n",
    "    for col in average:\n",
    "        if(row[col] == 0):\n",
    "            try:\n",
    "                newvalue = state_dict[(row[\"STATE_ABBR\"], row[\"PROD_LINE\"])]\n",
    "            except(ValueError): #No average can be found since its all 0\n",
    "                newvalue = 0 \n",
    "            df_average.set_value(index, col, newvalue[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average[average].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.STATE_ABBR.unique()\n",
    "statedict = {np.NaN : 0, \"IN\" : 1, \"KY\" : 2, \"MI\" : 3, \"OH\" : 4, \"PA\" : 5, \"WV\" : 6}\n",
    "df.PROD_ABBR.unique()\n",
    "proddict = {np.NaN : 0, \"BOILERMACH\" : 1, \"BOP\" : 2, \"COMMAUTO\" : 3, \"COMMINLMAR\" : 4, \"COMMPOL\": 5, \"COMMUMBREL\" : 6, \"CRIME\" : 7,\n",
    "           \"FIREALLIED\" : 8, \"GARAGE\" : 9, \"GENERALIAB\" : 10, \"WORKCOMP\" : 11, \"ANNIV\" : 12, \"ANNIV   12\":13, \"CYCLES\":14,\n",
    "           \"DTALK\":15, \"DWELLFIRE\":16, \"HOMEONWERS\":17,\"MOBILEHOME\":18,\"MOTORHOM12\":19,\"MOTORHOME\":20,\"PERSUMBREL\":21, \"YACHT\":22,\n",
    "           \"DTALK   12\":23, \"PERSINLMAR\":24, \"SNOWMOBILE\":25,\"CYCLES  12\":26,\"SNOWMOBBI12\":27,\"PERSAIP\":28}\n",
    "df.PROD_LINE.unique()\n",
    "prodlinedict = {np.NaN : 0, \"CL\":1, \"PL\":2}\n",
    "vendordict = {'Unknown': 0, 'A': 1, 'B':2, 'C' : 3, 'E':4}\n",
    "\n",
    "df['STATE_ID'] = df['STATE_ABBR'].map(statedict)\n",
    "df['PROD_ID'] = df[\"PROD_ABBR\"].map(proddict)\n",
    "df['PROD_LINE_ID'] = df['PROD_LINE'].map(prodlinedict)\n",
    "df['VENDOR_ID'] = df['VENDOR'].map(vendordict)\n",
    "df[[\"STATE_ABBR\", \"PROD_ABBR\", \"PROD_LINE\", \"VENDOR\", \"STATE_ID\", \"PROD_ID\", \"PROD_LINE_ID\", \"VENDOR_ID\"]].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split PL and CL datasets\n",
    "df_cl = df[df.PROD_LINE=='CL']\n",
    "df_pl = df[df.PROD_LINE=='PL']\n",
    "\n",
    "# remove irrelevant columns from splits\n",
    "df_cl = df_cl.filter(regex='^(?!PL_)\\w+', axis=1)\n",
    "df_pl = df_pl.filter(regex='^(?!CL_)\\w+', axis=1)\n",
    "\n",
    "# write dataframes to csv files\n",
    "df_cl.to_csv('cleaned_CL_'+filename)\n",
    "df_pl.to_csv('cleaned_PL_'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLY_GROWTH_RATIO = \n",
    "#PREM_GROWTH_RATIO = WRTN_PREM_AMT (Current)- WRTN_PREM_AMT (Last Year) / (Current + Last year)\n",
    "\n",
    "#index, row, df.itter\n",
    "#try:\n",
    "#   prevyear = df where(agencyid == id, prodid == prodid, prodline == prodline, year == currentyear-1)[columnname]\n",
    "#except:\n",
    "#prevyear = 0\n",
    "#if prevyear > 0\n",
    "#df put growthratio (this-prev/prev)\n",
    "\n",
    "column = \"POLY_INFORCE_QTY\"\n",
    "columnname= \"POLY_GROWTH_RATIO\"\n",
    "def GrowthRatioCalculator(df, column, columnname):\n",
    "    for index, row in df.iterrows():\n",
    "        if(index > 0): #Start off at 1 so we don't get an index of -1\n",
    "            prevyear = df.loc[index-1] #Get the previous item in the dataframe\n",
    "            if(prevyear[\"STATE_ABBR\"] == row[\"STATE_ABBR\"]) & (prevyear[\"PROD_LINE\"] == row[\"PROD_LINE\"]) & (prevyear[\"STAT_PROFILE_DATE_YEAR\"] == (row[\"STAT_PROFILE_DATE_YEAR\"]-1)) & (prevyear[\"AGENCY_ID\"] == row[\"AGENCY_ID\"])& (prevyear[\"PROD_ABBR\"] == row[\"PROD_ABBR\"]):\n",
    "                prevyear = prevyear[column] #Get the actual value of the previous year\n",
    "                try:\n",
    "                    if(prevyear > 0): #Check if its bigger than 0/ works\n",
    "                        df.set_value(index, columnname, (row[column] -prevyear)/prevyear) #Set the value in the column to be the percentage\n",
    "                        print((row[column] -prevyear)/prevyear) #Print out the value so we know it's working\n",
    "\n",
    "                except:\n",
    "                    #Can go wrong when we continue to a new product.\n",
    "                    #If there is a missmatch within the if statement and it returns false, it will generate a kind of null value.\n",
    "                    #We can not work with this value so it will throw an exception.\n",
    "                    #If it goes wrong, put a 0 in the dataframe.\n",
    "                    df.set_value(index, columnname, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
