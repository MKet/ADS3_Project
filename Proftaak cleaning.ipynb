{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('numpy version:', np.__version__)\n",
    "print('pandas version:', pd.__version__)\n",
    "print('scikit-learn version:', sk.__version__)\n",
    "print('matplotlib version:', matplotlib.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = 'data/'\n",
    "filename = 'dataset_informa.csv'\n",
    "df = pd.read_csv(datafolder + filename, sep=',', low_memory=False, encoding = 'ISO-8859-1')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RETENTION_RATIO'], axis = 1, inplace = True)\n",
    "\n",
    "# Primary_Agency_ID: When this column data is missing/99999 we are going to replace it with the Agency_ID. \n",
    "# We can not find any way to associate a primary agency with the agency in question so will replace it with its ID.\n",
    "df['PRIMARY_AGENCY_ID'] = np.where(df['PRIMARY_AGENCY_ID'] == 0, df['PRIMARY_AGENCY_ID'], df['AGENCY_ID'])\n",
    "\n",
    "# (VENDOR)_END _YEAR: The year the agency stopped using the vendor. \n",
    "# This can either mean the vendor is never used or the vendor is still in use. \n",
    "# If the vendor has never been used we can replace the value with 0, if the vendor is still in use we can replace it with 1.\n",
    "df['CL_END_YEAR'] = np.where(df['CL_START_YEAR'] == 0, 0, 1)\n",
    "df['PL_END_YEAR'] = np.where(df['PL_START_YEAR'] == 0, 0, 1)\n",
    "\n",
    "# Agency_appointment_year: 5000 missing data, irrelevant column, will be replaced with average.\n",
    "mean = df['AGENCY_APPOINTMENT_YEAR'].mean()\n",
    "df['AGENCY_APPOINTMENT_YEAR'].replace(99999, mean, inplace=True) \n",
    "\n",
    "# replace the rest of the 99999 values with 0\n",
    "df.replace(99999, 0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get a list of all values needing to be recalculated per item\n",
    "recal = [\"POLY_INFORCE_QTY\", \"NB_WRTN_PREM_AMT\", \"WRTN_PREM_AMT\", \"PRD_ERND_PREM_AMT\", \"PRD_INCRD_LOSSES_AMT\"]\n",
    "df_incomplete = df[(df[\"MONTHS\"] != 12)]\n",
    "df_filtered = df_incomplete\n",
    "for index, row in df_filtered.iterrows():\n",
    "    #Amount of months\n",
    "    months = row[\"MONTHS\"]\n",
    "    for column in recal:\n",
    "        newvalue = row[column] * (12 - months) #Value times amount of months missing\n",
    "        df_filtered.set_value(index, column, newvalue) #Set new row in dataset\n",
    "    row[\"MONTHS\"] = 12 #Reset the months to be 12\n",
    "df_filtered[recal].head(5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = df_filtered #Copy of the dataset for testing\n",
    "df_incomplete[recal].head(5) #Get incomplete rows in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETENTION_RATIO = RETENTION_POLY_QTY / PREV_POLY_INFORCE_QTYDataFrame.drop\n",
    "#LOSS_RATIO = PRD_INCRD_LOSSES_AMT / WRTN_PREM_AMT\n",
    "\n",
    "for index, row in df_filtered.iterrows():\n",
    "    if (row[\"WRTN_PREM_AMT\"] > 0) and (row[\"PRD_INCRD_LOSSES_AMT\"] > 0):\n",
    "        df_filtered.set_value(index, \"LOSS_RATIO\", row[\"PRD_INCRD_LOSSES_AMT\"] / row[\"WRTN_PREM_AMT\"])\n",
    "    else:\n",
    "        df_filtered.set_value(index, \"LOSS_RATIO\", 0)\n",
    "        \n",
    "df_filtered['LOSS_RATIO'].replace(99998, 0, inplace=True)\n",
    "df_filtered['LOSS_RATIO'].replace(99997, 0, inplace=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old[\"LOSS_RATIO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[[\"PRD_INCRD_LOSSES_AMT\",\"WRTN_PREM_AMT\",\"LOSS_RATIO\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[[\"RETENTION_POLY_QTY\",\"PREV_POLY_INFORCE_QTY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VENDOR_ID'] = df['VENDOR'].rank(method='dense', ascending=False).astype(int)\n",
    "df['STATE_ID'] = df['STATE_ABBR'].rank(method='dense', ascending=False).astype(int)\n",
    "df['PRODUCT_LINE_ID'] = df['PROD_LINE'].rank(method='dense', ascending=False).astype(int)\n",
    "df['PRODUCT_ID'] = df['PROD_ABBR'].rank(method='dense', ascending=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_average = df\n",
    "average = [\"PREV_POLY_INFORCE_QTY\",\"POLY_INFORCE_QTY\", \"NB_WRTN_PREM_AMT\", \"WRTN_PREM_AMT\", \"PRD_ERND_PREM_AMT\"]\n",
    "\n",
    "states = df_average.STATE_ABBR.unique()\n",
    "prod_line = df_average.PROD_LINE.unique()\n",
    "   \n",
    "state_dict = {}    \n",
    "for state in states:\n",
    "    for line in prod_line:\n",
    "        state_mean = df_average[(df_average[\"STATE_ABBR\"] == state) & (df_average[\"PROD_LINE\"] == line)].mean()\n",
    "        state_dict[(state, line)] = state_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_average.iterrows():\n",
    "    for col in average:\n",
    "        if(row[col] == 0):\n",
    "            try:\n",
    "                newvalue = state_dict[(row[\"STATE_ABBR\"], row[\"PROD_LINE\"])]\n",
    "            except(ValueError): #No average can be found since its all 0\n",
    "                newvalue = 0 \n",
    "            df_average.set_value(index, col, newvalue[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average[average].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average.replace(99999, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split PL and CL datasets\n",
    "df_cl = df[df.PROD_LINE=='CL']\n",
    "df_pl = df[df.PROD_LINE=='PL']\n",
    "\n",
    "# remove irrelevant columns from splits\n",
    "df_cl = df_cl.filter(regex='^(?!PL_)\\w+', axis=1)\n",
    "df_pl = df_pl.filter(regex='^(?!CL_)\\w+', axis=1)\n",
    "\n",
    "# write dataframes to csv files\n",
    "df_cl.to_csv('cleaned_CL_'+filename)\n",
    "df_pl.to_csv('cleaned_PL_'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
